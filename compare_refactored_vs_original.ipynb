{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b051b2-a8ef-4df9-9666-9bd47ca768b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrix_factorization import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6239906e-aac3-4da6-bfce-d301164b660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import surprise  # Only used for comparison and getting the dataset, not required to run refactored code\n",
    "from tqdm import tqdm  # Only used for timing purposes\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a44c3-2825-43dc-887b-1caf0757f9e1",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3930f0c-2151-499b-9a6f-e3e0e38ee791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = surprise.Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa3c3f8-7fe2-44ae-912c-a08f791d9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset.raw_ratings, columns=['user_id', 'item_id', 'ratings', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44fece4e-f313-4852-aad4-5e7b83039a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    100000 non-null  object \n",
      " 1   item_id    100000 non-null  object \n",
      " 2   ratings    100000 non-null  float64\n",
      " 3   timestamp  100000 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92463171-ac90-47cc-940c-7ceb51ae2b44",
   "metadata": {},
   "source": [
    "# Refactored Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e72a1-95f2-4012-b76d-da9beda95cdc",
   "metadata": {},
   "source": [
    "## Build model and predict train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2f6f7f-8dc2-4ef4-95ff-6217fe1963e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [00:29<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "new_predictions = []\n",
    "for i in tqdm(range(100)):\n",
    "    svd = SVD(n_factors=10, n_epochs=100, random_state=i)\n",
    "    svd.fit(X=df[['user_id', 'item_id']], y=df['ratings'])\n",
    "    new_predictions.append(svd.predict(df[['user_id', 'item_id']]))\n",
    "all_new_predictions = np.vstack(new_predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc305097-bac1-43e1-9829-f2bc609e7380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a column for each run\n",
    "all_new_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af2834-f889-4bd9-af1e-f5a9932bcdd9",
   "metadata": {},
   "source": [
    "# Surprise original package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc4f69-b5d1-4cad-a014-c0031d098563",
   "metadata": {},
   "source": [
    "## Create trainset (required for training) and helper function to score predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6524acb-c5c1-4595-8cb6-aeafdd168eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b0d329-e0b9-4f5e-b767-378c1992fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_surprise_svd_predictions(df, surprise_svd):\n",
    "    preds = []\n",
    "    for raw_user, raw_item in df[['user_id', 'item_id']].values:\n",
    "        preds.append(surprise_svd.estimate(trainset.to_inner_uid(raw_user), trainset.to_inner_iid(raw_item)))\n",
    "    return np.asarray(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d73ac7-6e28-420a-b23e-d61d4b1fe4dc",
   "metadata": {},
   "source": [
    "## Build model and predict train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81a2c3a-e29a-4ac7-bad0-5284c656143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "surprise_predictions = []\n",
    "for i in tqdm(range(100)):\n",
    "    surprise_svd = surprise.SVD(n_factors=10, n_epochs=100, random_state=i)\n",
    "    surprise_svd.fit(trainset)\n",
    "    surprise_predictions.append(get_df_surprise_svd_predictions(df, surprise_svd))\n",
    "all_surprise_predictions = np.vstack(surprise_predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61fdf13-e96a-4884-874d-2180617e9750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a column for each run\n",
    "all_surprise_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075003a0-1e64-419b-b1f5-8017386e1085",
   "metadata": {},
   "source": [
    "# Compare predictions from both models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb1a09-33a1-4fb5-a4fb-480e916f573d",
   "metadata": {},
   "source": [
    "## Compare rmse's by test run pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdca9d0b-81bd-4a92-9552-c430652705a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_is_better = []\n",
    "rmses = []\n",
    "for i in range(all_surprise_predictions.shape[1]):\n",
    "    new_rmse = root_mean_squared_error(df['ratings'], all_new_predictions[:, i])\n",
    "    surprise_rmse = root_mean_squared_error(df['ratings'], all_surprise_predictions[:, i])\n",
    "    rmses.append((new_rmse, surprise_rmse))\n",
    "    new_is_better.append(new_rmse < surprise_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c21487-9ba3-40e4-b2c4-944c10960e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### What % is new better than old (close to 50% is just random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5efd76-97c0-4185-b562-caa4b629bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_is_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4b0f95-3a36-4a50-983c-25f78eb7e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare the sum of all test run RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2080160-c7fd-40b9-b3d3-b08961834ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    71.040092\n",
       "1    71.037300\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rmses).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36339700-e5fa-4655-8ee1-4c508ddc60a3",
   "metadata": {},
   "source": [
    "## Pair every run and every rating and tabulate rate at which new is better (smaller abs error) than surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b16436-457b-4d88-83f8-d2c532f40f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_abs_errors = np.abs(all_new_predictions - df['ratings'].values.reshape(-1, 1))\n",
    "surprise_abs_errors = np.abs(all_surprise_predictions - df['ratings'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b281476-64b3-4fac-a756-771a2bfd5d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4997735"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_abs_errors < surprise_abs_errors).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c029266-a21e-420a-b1e2-352934328bef",
   "metadata": {},
   "source": [
    "## The distribution of the standard deviations among the test runs across all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "618552d3-950d-44e7-9ef7-03d844687f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.224764</td>\n",
       "      <td>0.223489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.088877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029090</td>\n",
       "      <td>0.015741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.158450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.210414</td>\n",
       "      <td>0.209205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.274993</td>\n",
       "      <td>0.273883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.849841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 new       surprise\n",
       "count  100000.000000  100000.000000\n",
       "mean        0.224764       0.223489\n",
       "std         0.088388       0.088877\n",
       "min         0.029090       0.015741\n",
       "25%         0.159804       0.158450\n",
       "50%         0.210414       0.209205\n",
       "75%         0.274993       0.273883\n",
       "max         0.898698       0.849841"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_distributions = pd.concat(\n",
    "    [pd.Series(all_new_predictions.std(1)).describe(),\n",
    "     pd.Series(all_surprise_predictions.std(1)).describe()], axis=1)\n",
    "std_distributions.columns = ['new', 'surprise']\n",
    "std_distributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
